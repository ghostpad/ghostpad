transformers[sentencepiece]==4.34.0
huggingface_hub==0.16.4
optimum[onnxruntime]==1.13.2
safetensors==0.3.3
Flask==2.3.3
Flask-SocketIO==5.3.2
Werkzeug==2.3.7
python-socketio==5.7.2
requests
torch == 2.0.*
flask-cloudflared==0.0.10
flask-ngrok
flask-cors
eventlet==0.33.3
dnspython==2.2.1
lupa==2.0
markdown
bleach==4.1.0
protobuf
accelerate==0.21.0
flask-session==0.5.0
marshmallow>=3.13
apispec-webframeworks
loguru
termcolor
git+https://github.com/VE-FORBRYDERNE/mkultra
Pillow
diffusers
psutil
ansi2html
flask_compress
ijson
bitsandbytes==0.40.0.post4; sys_platform == 'linux'
https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.0.post4-py3-none-win_amd64.whl; sys_platform == 'win32'
ftfy
pydub
pytest==7.2.2
pytest-html==3.2.0
pytest-metadata==2.0.4
requests-mock==1.10.0
git+https://github.com/0cc4m/hf_bleeding_edge/
einops
peft==0.3.0
scipy
https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux' and python_version == '3.10'
https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-win_amd64.whl; sys_platform == 'win32' and python_version == '3.10'
https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux' and python_version == '3.10'
https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.7/autoawq-0.1.7+cu118-cp310-cp310-win_amd64.whl; sys_platform == 'win32' and python_version == '3.10'
exllamav2==0.0.7
windows-curses; sys_platform == 'win32'
pynvml
https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.4/flash_attn-2.3.4+cu118torch2.0cxx11abiFALSE-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux'
xformers==0.0.21
omegaconf
https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.20+cpuavx-cp310-cp310-manylinux_2_31_x86_64.whl; sys_platform == "linux" and platform_machine == "x86_64" and python_version == "3.10"
https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.20+cpuavx-cp310-cp310-win_amd64.whl; sys_platform == "win32" and python_version == "3.10"
https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/metal/llama_cpp_python-0.2.20-cp310-cp310-macosx_14_0_arm64.whl; sys_platform == "darwin" and python_version == "3.10"
