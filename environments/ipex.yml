name: koboldai
channels:
  - conda-forge
  - defaults
dependencies:
  - colorama
  - flask=2.3.3
  - flask-socketio=5.3.2
  - flask-session=0.5.0
  - python-socketio=5.7.2
  - python=3.8.*
  - eventlet=0.33.3
  - dnspython=2.2.1
  - markdown
  - bleach=4.1.0
  - pip
  - git=2.35.1
  - protobuf
  - marshmallow>=3.13
  - apispec-webframeworks
  - loguru
  - termcolor
  - Pillow
  - psutil
  - ffmpeg
  - pip:
    - --extra-index-url https://pytorch-extension.intel.com/release-whl/stable/xpu/us/
    - torch==2.0.1a0; sys_platform == 'linux'
    - torch==2.0.0a0; sys_platform == 'win32'
    - intel_extension_for_pytorch==2.0.110+xpu; sys_platform == 'linux'
    - intel_extension_for_pytorch==2.0.110+gitba7f6c1; sys_platform == 'win32'
    - intel-extension-for-transformers
    - flask-cloudflared==0.0.10
    - flask-ngrok
    - flask-cors
    - lupa==2.0
    - transformers[sentencepiece]==4.34.0
    - Werkzeug==2.3.7
    - huggingface_hub==0.16.4
    - optimum[onnxruntime,openvino,nncf,neural-compressor]==1.13.2
    - safetensors==0.3.3
    - accelerate==0.21.0
    - git+https://github.com/VE-FORBRYDERNE/mkultra
    - flask-session
    - ansi2html
    - flask_compress
    - ijson
    - ftfy
    - pydub
    - diffusers
    - git+https://github.com/0cc4m/hf_bleeding_edge/
    - https://github.com/0cc4m/GPTQ-for-LLaMa/archive/refs/tags/0.0.6.tar.gz
    - https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux'
    - https://github.com/PanQiWei/AutoGPTQ/releases/download/v0.4.2/auto_gptq-0.4.2+cu118-cp310-cp310-win_amd64.whl; sys_platform == 'win32'
    - einops
    - peft==0.3.0
    - scipy
    - https://github.com/0cc4m/exllama/archive/refs/tags/0.0.7.tar.gz
    - windows-curses; sys_platform == 'win32'
    - pynvml
    - omegaconf
    - https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.20+cpuavx-cp310-cp310-manylinux_2_31_x86_64.whl; sys_platform == "linux" and platform_machine == "x86_64" and python_version == "3.10"
    - https://github.com/jllllll/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.20+cpuavx-cp310-cp310-win_amd64.whl; sys_platform == "win32" and python_version == "3.10"