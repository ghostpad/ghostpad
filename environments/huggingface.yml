name: koboldai
channels:
  - pytorch
  - nvidia/label/cuda-11.8.0
  - conda-forge
  - defaults
dependencies:
  - colorama
  - flask=2.3.3
  - flask-socketio=5.3.2
  - flask-session=0.5.0
  - gekko
  - python-socketio=5.7.2
  - pytorch=2.2.*
  - python=3.10.*
  - pytorch-cuda=11.8
  - cuda-nvcc=11.8
  - cuda-libraries-dev=11.8
  - eventlet=0.33.3
  - dnspython=2.2.1
  - markdown
  - numpy
  - bleach=4.1.0
  - pip
  - git=2.35.1
  - pandas
  - protobuf
  - marshmallow>=3.13
  - apispec-webframeworks
  - loguru
  - termcolor
  - Pillow
  - psutil
  - ffmpeg
  - pip:
    - flask-cloudflared==0.0.10
    - flask-ngrok
    - flask-cors
    - lupa==2.0
    - transformers[sentencepiece]==4.38.0
    - Werkzeug==2.3.7
    - huggingface_hub==0.19.4
    - optimum[onnxruntime]==1.13.2
    - safetensors==0.4.1
    - accelerate==0.27.2
    - git+https://github.com/VE-FORBRYDERNE/mkultra
    - flask-session
    - ansi2html
    - flask_compress
    - ijson
    - bitsandbytes==0.40.0.post4; sys_platform == 'linux'
    - https://github.com/jllllll/bitsandbytes-windows-webui/releases/download/wheels/bitsandbytes-0.40.0.post4-py3-none-win_amd64.whl; sys_platform == 'win32'
    - ftfy
    - pydub
    - diffusers
    - auto-gptq
    - https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.8/autoawq-0.1.8+cu118-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux' and python_version == '3.10'
    - https://github.com/casper-hansen/AutoAWQ/releases/download/v0.1.8/autoawq-0.1.8+cu118-cp310-cp310-win_amd64.whl; sys_platform == 'win32' and python_version == '3.10'
    - einops
    - peft==0.7.1
    - scipy
    - https://github.com/turboderp/exllamav2/releases/download/v0.0.11/exllamav2-0.0.11-py3-none-any.whl
    - windows-curses; sys_platform == 'win32'
    - pynvml
    - xformers==0.0.24
    - https://github.com/Dao-AILab/flash-attention/releases/download/v2.5.4/flash_attn-2.5.4+cu118torch2.2cxx11abiFALSE-cp310-cp310-linux_x86_64.whl; sys_platform == 'linux'
    - omegaconf
    - https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.50+cpuavx-cp310-cp310-manylinux_2_31_x86_64.whl; sys_platform == "linux" and platform_machine == "x86_64" and python_version == "3.10"
    - https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.50+cpuavx-cp310-cp310-win_amd64.whl; sys_platform == "win32" and python_version == "3.10"


